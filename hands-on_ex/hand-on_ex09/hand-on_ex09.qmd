---
title: "Hands-on Exercise 9: Geographical Segmentation with Spatially Constrained Clustering Techniques"
date: "11 March 2023"
date-modified: "`r Sys.Date()`"
execute: 
  eval: true
  echo: true
  warning: false
editor: visual
---

# 1.0 Overview

To do -

-   hierarchical cluster analysis; and

-   spatially constrained cluster analysis.

## 1.1 The analytical question

In geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data. In this hands-on exercise, we are interested to delineate [Shan State](https://en.wikipedia.org/wiki/Shan_State), [Myanmar](https://en.wikipedia.org/wiki/Myanmar) into homogeneous regions by using multiple Information and Communication technology (ICT) measures, namely: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home.

## 1.2 The Data

-   Myanmar Township Boundary Data (i.e.Â *myanmar_township_boundaries*) : This is a GIS data in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features.

-   *Shan-ICT.csv*: This is an extract of [**The 2014 Myanmar Population and Housing Census Myanmar**](https://myanmar.unfpa.org/en/publications/2014-population-and-housing-census-myanmar-data-sheet) at the township level.

## 1.3 Load Packages

```{r}
pacman::p_load(rgdal, spdep, tmap, sf, ClustGeo, 
               ggpubr, cluster, factoextra, NbClust,
               heatmaply, corrplot, psych, tidyverse, GGally)
```

# 2.0 Data Import and Preparation 

## 2.1 Geospatial Data

::: panel-tabset
#### Import

```{r}
shan_sf <- st_read(dsn = "data/geospatial", 
                   layer = "mmr_polbnda_adm3_250k_mimu") %>%
  filter(ST %in% c("Shan (East)", "Shan (North)", "Shan (South)")) %>%
  select(c(2:7))
```

#### View

```{r}
shan_sf
```

#### Glimpse

```{r}
glimpse(shan_sf)
```
:::

## 2.2 Aspatial Data

::: panel-tabset
#### Import

```{r}
ict <- read_csv ("data/aspatial/censuscommuniationtsp.csv") %>% 
   filter(name_st == "Shan") %>% #Filter Shan district values
   select(-c(1,2)) %>% #Remove district columns
    rename(`District Pcode` = "pcode_dt", #Rename columns
           `District Name` = "name_dt",
           `Township Pcode` = "pcode_ts",
           `Township Name` = "name_ts",
           `Total households` = "com_t",
           `Radio` = "com_radio",
           `Television` = "com_tv",
           `Land line phone` = "com_lline",
           `Mobile phone` = "com_mob",
           `Computer` = "com_comp",
           `Internet at home` = "com_int")
```

#### Summary

```{r}
summary(ict)
```

There are a total of eleven fields and 55 observation in the tibble data.frame.
:::

## 2.3 Derive new variables

Use penetration rate (%) instead of absolute values to reduce bias

::: panel-tabset
#### Derive

```{r}
ict_derived <- ict %>%
  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %>%
  mutate(`TV_PR` = `Television`/`Total households`*1000) %>%
  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %>%
  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %>%
  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %>%
  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %>%
  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,
         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,
         `TT_HOUSEHOLDS`=`Total households`,
         `RADIO`=`Radio`, `TV`=`Television`, 
         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,
         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) 
```

#### Summary

```{r}
summary(ict_derived)
```
:::

# 3.0 Exploratory Data Analysis (EDA)

## 3.1 EDA using statistical graphics

**View for Radio**

::: panel-tabset
#### Distribution

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")
```

#### Boxplot

To visualise outliers

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO`)) +
  geom_boxplot(color="black", 
               fill="light blue")
```
:::

**View for Radio Penetration Rate**

::: panel-tabset
#### Distribution

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")
```

#### Boxplot

To visualise outliers

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO_PR`)) +
  geom_boxplot(color="black", 
               fill="light blue")
```
:::

**View All**

```{r}
#| code-fold: true
radio <- ggplot(data=ict_derived, 
             aes(x= `RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

tv <- ggplot(data=ict_derived, 
             aes(x= `TV_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

llphone <- ggplot(data=ict_derived, 
             aes(x= `LLPHONE_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

mphone <- ggplot(data=ict_derived, 
             aes(x= `MPHONE_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

computer <- ggplot(data=ict_derived, 
             aes(x= `COMPUTER_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

internet <- ggplot(data=ict_derived, 
             aes(x= `INTERNET_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

ggarrange(radio, tv, llphone, mphone, computer, internet, 
          ncol = 3, 
          nrow = 2)
```

## 3.2 EDA using choropleth map

### 3.2.1 Join geospatial and aspatial data

```{r}
shan_sf <- left_join(shan_sf, 
                     ict_derived, by=c("TS_PCODE"="TS_PCODE"))
  
#store
write_rds(shan_sf, "data/rds/shan_sf.rds")
```

Store as rds

```{r}
shan_sf <- read_rds("data/rds/shan_sf.rds")
```

### 3.2.2 Preparing a choropleth map

Quantile mapping

```{r}
qtm(shan_sf, "RADIO_PR")
```

View comparison

```{r}
TT_HOUSEHOLDS.map <- tm_shape(shan_sf) + 
  tm_fill(col = "TT_HOUSEHOLDS",
          n = 5,
          style = "jenks", 
          title = "Total households") + 
  tm_borders(alpha = 0.5) 

RADIO.map <- tm_shape(shan_sf) + 
  tm_fill(col = "RADIO",
          n = 5,
          style = "jenks",
          title = "Number Radio ") + 
  tm_borders(alpha = 0.5) 

tmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,
             asp=NA, ncol=2)
```

Townships with relatively larger number of households are also showing relatively higher number of radio ownership.

Use jenks breaks

```{r}
tm_shape(shan_sf) +
    tm_polygons(c("TT_HOUSEHOLDS", "RADIO_PR"),
                style="jenks") +
    tm_facets(sync = TRUE, ncol = 2) +
  tm_legend(legend.position = c("right", "bottom"))+
  tm_layout(outer.margins=0, asp=0)
```

Maps have less colour variation - data is more evenly distributed

# 4.0 Correlation Analysis

Check for multicollinearity

```{r}
cluster_vars.cor = cor(ict_derived[,12:17])
corrplot.mixed(cluster_vars.cor,
         lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               tl.col = "black")
```

COMPUTER_PR and INTERNET_PR are highly correlated

# 5.0 Hierarchy Cluster Analysis

## 5.1 Extracting clustering variables

Exclude INTERNET_PR due to high correlation with COMPUTER_PR

```{r}
cluster_vars <- shan_sf %>%
  st_set_geometry(NULL) %>%
  select("TS.x", "RADIO_PR", "TV_PR", "LLPHONE_PR", "MPHONE_PR", "COMPUTER_PR")
head(cluster_vars,10)
```

Change index to township name

```{r}
row.names(cluster_vars) <- cluster_vars$"TS.x"
head(cluster_vars,10)
```

Remove duplicate column

```{r}
shan_ict <- select(cluster_vars, c(2:6))
head(shan_ict, 10)
```

## 5.2 Data Standardisation

### 5.2.1 Min-Max standardisation

All values to range between 0 - 1

```{r}
shan_ict.std <- normalize(shan_ict)
summary(shan_ict.std)
```

### 5.2.2 Z-score standardisation

(Assumes normal distribution)

Mean and stdev are 0 and 1 respectively

```{r}
shan_ict.z <- scale(shan_ict)
describe(shan_ict.z)
```

### 5.2.3 Visualising the standardised clustering variables

```{r}
#| code-fold: true
r <- ggplot(data=ict_derived, 
             aes(x= `RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Raw values without standardisation")

shan_ict_s_df <- as.data.frame(shan_ict.std)
s <- ggplot(data=shan_ict_s_df, 
       aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Min-Max Standardisation")

shan_ict_z_df <- as.data.frame(shan_ict.z)
z <- ggplot(data=shan_ict_z_df, 
       aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Z-score Standardisation")

ggarrange(r, s, z,
          ncol = 3,
          nrow = 1)
```

```{r}
#| code-fold: true
r <- ggplot(data=ict_derived, 
             aes(x= `RADIO_PR`)) +
  geom_density(color="black",
               fill="light blue") +
  ggtitle("Raw values without standardisation")

shan_ict_s_df <- as.data.frame(shan_ict.std)
s <- ggplot(data=shan_ict_s_df, 
       aes(x=`RADIO_PR`)) +
  geom_density(color="black",
               fill="light blue") +
  ggtitle("Min-Max Standardisation")

shan_ict_z_df <- as.data.frame(shan_ict.z)
z <- ggplot(data=shan_ict_z_df, 
       aes(x=`RADIO_PR`)) +
  geom_density(color="black",
               fill="light blue") +
  ggtitle("Z-score Standardisation")

ggarrange(r, s, z,
          ncol = 3,
          nrow = 1)
```

## 5.3 Computing proximity matrix

```{r}
proxmat <- dist(shan_ict, method = 'euclidean')
```

```{r}
#proxmat
```

## 5.4 Computing hierarchical clustering

### 5.4.1 Perform hierarchical cluster analysis 

Use ward.D method

```{r}
hclust_ward <- hclust(proxmat, method = 'ward.D')
```

```{r}
plot(hclust_ward, cex = 0.6)
```

### 5.4.2 Select Optimal clustering algorithm

```{r}
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

ac <- function(x) {
  agnes(shan_ict, method = x)$ac
}

map_dbl(m, ac)
```

Ward\'s method provides the strongest clustering structure among the four methods assessed hence Ward's method will be used.

### 5.4.3 Determining Optimal Clusters

#### 5.4.3.1 Gap Statistic Method

The [**gap statistic**](http://www.web.stanford.edu/~hastie/Papers/gap.pdf) compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.

```{r}
set.seed(12345)
gap_stat <- clusGap(shan_ict, 
                    FUN = hcut, 
                    nstart = 25, 
                    K.max = 10, 
                    B = 50)
# Print the result
print(gap_stat, method = "firstmax")
```

**Plot**

```{r}
fviz_gap_stat(gap_stat)
```

With reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.

### 5.4.4 Interpreting the dendrograms

In the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.

The height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.

```{r}
plot(hclust_ward, cex = 0.6)
rect.hclust(hclust_ward, 
            k = 6, 
            border = 2:5)
```

### 5.4.5 Visually-driven hierarchical clustering analysis

Transforming the data frame into a matrix

```{r}
shan_ict_mat <- data.matrix(shan_ict)
```

Plot interactive map

```{r}
heatmaply(normalize(shan_ict_mat),
          Colv=NA,
          dist_method = "euclidean",
          hclust_method = "ward.D",
          seriate = "OLO",
          colors = Blues,
          k_row = 6,
          margins = c(NA,200,60,NA),
          fontsize_row = 4,
          fontsize_col = 5,
          main="Geographic Segmentation of Shan State by ICT indicators",
          xlab = "ICT Indicators",
          ylab = "Townships of Shan State"
          )
```

### 5.4.6 Mapping the clusters formed

```{r}
groups <- as.factor(cutree(hclust_ward, k=6))
```

Convert groups list to a matrix and append to shan_sf

```{r}
shan_sf_cluster <- cbind(shan_sf, as.matrix(groups)) %>%
  rename(`CLUSTER`=`as.matrix.groups.`)
```

```{r}
qtm(shan_sf_cluster, "CLUSTER")
```

The choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used.

# 6.0 Spatially Constrained Clustering: SKATER approach

## 6.1 Converting into SpatialPolygonsDataFrame

```{r}
shan_sp <- as_Spatial(shan_sf)
```

## 6.2 Computing Neighbour List

```{r}
shan.nb <- poly2nb(shan_sp)
summary(shan.nb)
```

Plot neighbor list object, with coordinates applied to the original shan_sp (to extract the centroids of the polygons)

```{r}
plot(shan_sp, 
     border=grey(.5))
plot(shan.nb, 
     coordinates(shan_sp), 
     col="blue", 
     add=TRUE)
```

## 6.3 Computing minimum spanning tree

### 6.3.1 Calculating edge costs

```{r}
lcosts <- nbcosts(shan.nb, shan_ict)
```

For each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighbouring observation (from the neighbour list). Basically, this is the notion of a generalised weight for a spatial weights matrix.

Incorporate into weights object

```{r}
shan.w <- nb2listw(shan.nb, 
                   lcosts, 
                   style="B")
summary(shan.w)
```

### 6.3.2 Computing minimum spanning tree

Minimum spanning tree is computed by mean of the [*mstree()*](https://r-spatial.github.io/spdep/reference/mstree.html)

```{r}
shan.mst <- mstree(shan.w)
```

Check class and dimension

```{r}
class(shan.mst)
```

```{r}
dim(shan.mst)
```

Note that the dimension is 54 and not 55. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.

**View**

```{r}
head(shan.mst)
```

Plot - include observation numbers

```{r}
plot(shan_sp, border=gray(.5))
plot.mst(shan.mst, 
         coordinates(shan_sp), 
         col="blue", 
         cex.lab=0.7, 
         cex.circles=0.005, 
         add=TRUE)
```

## 6.4 Computing spatially constrained clusters using SKATER method

```{r}
clust6 <- spdep::skater(edges = shan.mst[,1:2], 
                 data = shan_ict, 
                 method = "euclidean", 
                 ncuts = 5) #n clusters - 1
```

**View**

```{r}
str(clust6)
```

The most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label itself is arbitary). This is followed by a detailed summary for each of the clusters in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.

Check cluster assignment

```{r}
ccs6 <- clust6$groups
ccs6
```

#### **Plot pruned tree**

```{r}
plot(shan_sp, border=gray(.5))
plot(clust6, 
     coordinates(shan_sp), 
     cex.lab=.7,
     groups.colors=c("red","green","blue", "brown", "pink"),
     cex.circles=0.005, 
     add=TRUE)
```

## 6.5 Visualising the clusters in choropleth map

```{r}
groups_mat <- as.matrix(clust6$groups)
shan_sf_spatialcluster <- cbind(shan_sf_cluster, as.factor(groups_mat)) %>%
  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)
qtm(shan_sf_spatialcluster, "SP_CLUSTER")
```

**View hierarchical clustering and spatially constrained hierarchical clustering maps**

```{r}
#| code-fold: true
hclust.map <- qtm(shan_sf_cluster,
                  "CLUSTER") + 
  tm_borders(alpha = 0.5) 

shclust.map <- qtm(shan_sf_spatialcluster,
                   "SP_CLUSTER") + 
  tm_borders(alpha = 0.5) 

tmap_arrange(hclust.map, shclust.map,
             asp=NA, ncol=2)
```

# 7.0 Spatially Constrained Clustering: ClustGeo Method

The algorithm uses two dissimilarity matrices D0 and D1 along with a mixing parameter alpha, whereby the value of alpha must be a real number between \[0, 1\]. D0 can be non-Euclidean and the weights of the observations can be non-uniform. It gives the dissimilarities in the **attribute/clustering variable space**. D1, on the other hand, gives the dissimilarities in the **constraint space**. The criterion minimised at each stage is a convex combination of the homogeneity criterion calculated with D0 and the homogeneity criterion calculated with D1.

The idea is then to determine a value of alpha which increases the spatial contiguity without deteriorating too much the quality of the solution based on the variables of interest.

## 7.1 Ward-like hierarchical clustering: ClustGeo

```{r}
nongeo_cluster <- hclustgeo(proxmat) #has to be type dist
plot(nongeo_cluster, cex = 0.5)
rect.hclust(nongeo_cluster, 
            k = 6, 
            border = 2:5)
```

### 7.1.1 Mapping the clusters formed

```{r}
groups <- as.factor(cutree(nongeo_cluster, k=6))

shan_sf_ngeo_cluster <- cbind(shan_sf, as.matrix(groups)) %>%
  rename(`CLUSTER` = `as.matrix.groups.`)

qtm(shan_sf_ngeo_cluster, "CLUSTER")
```

## 7.2 Spatially Constrained Hierarchical Clustering

Derive spatial distance matrix

```{r}
dist <- st_distance(shan_sf, shan_sf)
distmat <- as.dist(dist) #convert df to dist
```

Choose a suitable value for the mixing parameter alpha

```{r}
cr <- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)
```

alpha = 0.3 will be used

```{r}
clustG <- hclustgeo(proxmat, distmat, alpha = 0.3)
```

Derive cluster object

```{r}
groups <- as.factor(cutree(clustG, k=6))
```

Join with shan_sf polygon feature

```{r}
shan_sf_Gcluster <- cbind(shan_sf, as.matrix(groups)) %>%
  rename(`CLUSTER` = `as.matrix.groups.`)
```

**Plot**

```{r}
qtm(shan_sf_Gcluster, "CLUSTER")
```

# 8.0 Visual Interpretation of Clusters

## 8.1 Visualising individual clustering variable

Clustering variable - RADIO_PR

```{r}
ggplot(data = shan_sf_ngeo_cluster,
       aes(x = CLUSTER, y = RADIO_PR)) +
  geom_boxplot()
```

The boxplot reveals Cluster 3 displays the highest mean Radio Ownership Per Thousand Household. This is followed by Cluster 2, 1, 4, 6 and 5.

## 8.2 Multivariate Visualisation

```{r}
#| code-fold: true
ggparcoord(data = shan_sf_ngeo_cluster, 
           columns = c(17:21), 
           scale = "globalminmax",
           alphaLines = 0.2,
           boxplot = TRUE, 
           title = "Multiple Parallel Coordinates Plots of ICT Variables by Cluster") +
  facet_grid(~ CLUSTER) + 
  theme(axis.text.x = element_text(angle = 30))
```

The parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.

**Summary**

```{r}
shan_sf_ngeo_cluster %>% 
  st_set_geometry(NULL) %>%
  group_by(CLUSTER) %>%
  summarise(mean_RADIO_PR = mean(RADIO_PR),
            mean_TV_PR = mean(TV_PR),
            mean_LLPHONE_PR = mean(LLPHONE_PR),
            mean_MPHONE_PR = mean(MPHONE_PR),
            mean_COMPUTER_PR = mean(COMPUTER_PR))
```

\
