---
title: "Take Home Exercise 3"
date: "22 March 2023"
date-modified: "`r Sys.Date()`"
execute: 
  eval: true
  echo: true
  warning: false
editor: visual
---

# 1.0 Overview

------------------------------------------------------------------------

## 1.1 Background

HDB Pricing

## 1.2 Task

In this take-home exercise, you are tasked to predict HDB resale prices at the sub-market level (i.e.Â HDB 3-room, HDB 4-room and HDB 5-room) for the month of January and February 2023 in Singapore. The predictive models must be built by using by using conventional OLS method and GWR methods. You are also required to compare the performance of the conventional OLS method versus the geographical weighted methods.

# 2.0 Setup

------------------------------------------------------------------------

## 2.1 Import Packages

-   sf - Used for handling geospatial data

-   sfdep - Used for functions not in spdep

-   tmap, maptools, kableExtra, plotly - Used for visualizing dataframes and plots

-   lubridate - Used for handling datetime

-   tidyr - Used for changing the shape and hierarchy of dataframe

-   readxl - to read excel data (.xlsx files)

-   tidyVerse - Used for data transformation and presentation

```{r}
pacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary, sfdep, onemapsgapi, stringr, httr, rjson, plotly, ggplot2, GGally, units, matrixStats)
```

# 3.0 Data Wrangling

------------------------------------------------------------------------

## 3.1 Datasets Used

| Type       | Name                                                                                                    |
|------------|---------------------------------------------------------------------------------------------------------|
| Aspatial   | [HDB Resale Data](https://data.gov.sg/dataset/resale-flat-prices)                                       |
| Geospatial | [Singapore Subzones (base layer)](https://data.gov.sg/dataset/master-plan-2014-subzone-boundary-web)    |
| Geospatial | [Bus Stops](https://datamall.lta.gov.sg/content/datamall/en/search_datasets.html?searchText=bus%20stop) |
| Geospatial | [MRT Station Exits](https://data.gov.sg/dataset/lta-mrt-station-exit)                                   |
| Geospatial | [Kindergartens](https://www.onemap.gov.sg/docs/#onemap-rest-apis)                                       |
| Geospatial | [Childcare](https://www.onemap.gov.sg/docs/#onemap-rest-apis)                                           |
| Geospatial | [Primary Schools](https://www.onemap.gov.sg/docs/#onemap-rest-apis)                                     |
| Geospatial | [Sports Facilities](https://www.onemap.gov.sg/docs/#onemap-rest-apis)                                   |
| Geospatial | [Parks](https://data.gov.sg/dataset/parks)                                                              |
| Geospatial | [Gyms](https://data.gov.sg/dataset/gymssg)                                                              |
| Geospatial | [Water Sites](https://data.gov.sg/dataset/abc-waters-sites)                                             |
| Geospatial | [Hawker Centers](https://data.gov.sg/dataset/hawker-centres)                                            |
| Geospatial | [Supermarkets](https://data.gov.sg/dataset/supermarkets)                                                |
| Geospatial | [Eldercare](https://www.onemap.gov.sg/docs/#onemap-rest-apis)                                           |
| Geospatial | [Waste Disposal](https://data.gov.sg/dataset/waste-treatment)                                           |
| Geospatial | [Active Cemeteries](https://data.gov.sg/dataset/active-cemeteries)                                      |
| Geospatial | [Historic Sites](https://data.gov.sg/dataset/historic-sites)                                            |

## 3.2 Aspatial Data

### 3.2.1 Load Data

::: panel-tabset
#### Import

```{r}
#| eval: false
resale <- read_csv("data/aspatial/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv")
```

#### Glimpse

```{r}
#| eval: false
glimpse(resale)
```

![](glimpse_resale.png)
:::

The dataset is based on the period of Jan 2017 to March 2023. It contains 11 columns with 149,071 rows.

### 3.2.2 Filter Data

The flat type has a high significance (p-value) of 2e-16 at 95% confidence level. This would impact the significance of all the other variables so the data is to be further split.

```{r}
#| eval: false
summary(aov(resale_price ~ flat_type, data = resale))
```

![](aov.png)

This exercise will use four bedroom flats only and for a shorter time period - Jan 01 2021 to Dec 31 2022 for train data and Jan 01 2023 to Feb 28 2023 for test data.

::: panel-tabset
#### Filter

```{r}
#| eval: false
resale <- resale %>% 
  filter(flat_type == "3 ROOM") %>%
  filter(month >= "2021-01" & month <= "2022-12" | month >= "2023-01" & month <= "2023-02")
```

#### Glimpse

```{r}
#| code-fold: true
c = 13778 #nrow(resale)
cat("The dataset now contains", c, "rows.")
```
:::

### 3.2.3 Remove Outliers

Based on the boxplot below, there appear several outliers in resale_price of the 3 bedroom HDB units, especially on the higher side.

```{r}
#| eval: false
#| code-fold: true

plot <- ggplotly(ggplot(resale, aes(y= resale_price)) +
  geom_boxplot())

write_rds(plot, "data/aspatial/rds/boxplot.rds")

```

```{r}
plot <- read_rds("data/aspatial/rds/boxplot.rds")
plot
```

```{r}
#| code-fold: true
c = 683900 #quantile(resale$resale_price, .95) + 1.5 * IQR(resale$resale_price)
cat("Top 5% of resale prices are over -", c)
```

These outliers can induce a bias so the data points of the top 5% resale prices (prices over \$683,900) will be removed.

```{r}
#| eval: false
#| code-fold: true
is_outlier <- function(x) {
  return(x > quantile(x, 0.95) + 1.5 * IQR(x))
}
resale <- resale %>%
  mutate(outlier = ifelse(is_outlier(resale_price),  as.numeric(NA), 1))

resale <- na.omit(resale)
```

```{r}
#| code-fold: true
c = 13618 #nrow(resale)
cat("The dataset now contains", c, "rows.")
```

### 3.2.4 Clean Up Variables

#### 3.2.4.1 Street Address

Extract full address with joint block and street name. This will later be used to get the corresponding latitude and longitude of the addresses.

```{r}
#| eval: false
resale <- resale %>%
  mutate(resale, address = paste(block,street_name))
```

#### 3.2.4.2 Remaining Lease

Extract numeric value of remaining lease from text

```{r}
#| eval: false
#| code-fold: true
str_list <- str_split(resale$remaining_lease, " ")
c = 1 #index counter

for(i in str_list) {
  year <- as.numeric(i[1])
  month = 0
  if(length(i) > 2) { #x years y months
    month <- as.numeric(i[3])
  }
  resale$remaining_lease[c] <- (year + round(month/12, 2))
  c = c + 1
}

resale<- resale |> 
  mutate(remaining_lease=as.numeric(remaining_lease))
```

#### 3.2.4.3 Floor Level

The storey_range is a categorical variable with 15 categories - "01 TO 03", "04 TO 06" upto "43 TO 45". Keeping them as separate categories would induce high carnality into the model.

The distribution of the storey_range is as follows -

```{r}
#| eval: false
#| code-fold: true
ggplot(resale, aes(x= storey_range)) +
  geom_bar() +
  scale_x_discrete(guide = guide_axis(n.dodge=2))
```

![](barplot.png){width="1053"}

For ease of use and to lower the carnality, the data will be categorised into 3 divisions - 1,2,3 which would correspond to storeys 01-06, 07-12 and 13-45

```{r}
#| eval: false
#| code-fold: true
#get ordinal data of storey_range
storey_text <- unique(resale$storey_range)
storey_cat <- c(1,1,2,2, rep(3, 11))

#set label
resale$storey_num <- storey_cat[match(resale$storey_range, storey_text)] 
levels(resale$storey_num) <- storey_text

#change column to categorical data type
resale<- resale |> 
  mutate(storey_num=as.factor(storey_num))
```

### 3.2.5 Data Visualisation

Visualise how ressale_price pairs with all other numeric variables

```{r}
#| eval: false
#| code-fold: true
pairs <- ggpairs(resale |> select(floor_area_sqm, remaining_lease, storey_num, resale_price))
plots <- lapply(1:pairs$ncol, function(j) getPlot(pairs, i = 4, j = j))
ggmatrix(
    plots,
    nrow = 1,
    ncol = pairs$ncol,
    xAxisLabels = pairs$xAxisLabels,
    yAxisLabels = "resale_price"
)
```

![](pairplot.png)

Based on an initial glance, higher floor_area_sqm seems to increase resale price, remaining_lease seems to have a mixed impact, and higher storey_num seems to increase resale_price.

### 3.2.6 Get Latitude and Longitude

Extract latitude, longitude and postal code of all addresses and store into temporary data frame for further inspection

```{r}
#| eval: false
#| code-fold: true
#list of addresses
add_list <- sort(unique(resale$address))

#dataframe to store api data
postal_coords <- data.frame()

for (i in add_list) {
  
  r <- GET('https://developers.onemap.sg/commonapi/search?',
           query=list(searchVal=i,
                     returnGeom='Y',
                     getAddrDetails='Y'))
  
  data <- fromJSON(rawToChar(r$content))
  
  found <- data$found
  res <- data$results
  
  if (found > 0){
      postal <- res[[1]]$POSTAL 
      lat <- res[[1]]$LATITUDE
      lng <- res[[1]]$LONGITUDE
      
      new_row <- data.frame(address= i, postal = postal, latitude = lat, longitude = lng)
  }
  else {
    new_row <- data.frame(address= i, postal = NA, latitude = NA, longitude = NA)
  }
  postal_coords <- rbind(postal_coords, new_row)
}
```

#### 3.2.6.1 Check for missing values

```{r}
#| eval: false
postal_coords[(is.na(postal_coords$postal) | is.na(postal_coords$latitude) | is.na(postal_coords$longitude) | postal_coords$postal=="NIL"), ]
```

![](missing.png)

After looking up the addresses on Google Maps, these were postal codes found.

| address             | postal |
|---------------------|--------|
| 154 HOUGANG ST 11   | 530154 |
| 220 SERANGOON AVE 4 | 550220 |
| 273 TAMPINES ST 22  | 520273 |
| 304 UBI AVE 1       | 400304 |
| 83 LOR 2 TOA PAYOH  | 310083 |

Append found postal codes to the postal coords data frame

```{r}
#| eval: false
#| code-fold: true
indices = c(468, 812, 1051, 1154, 2468)
postal_codes = c("530154", "550220", "520273", "400304")

for (i in 1:length(indices)) {
  postal_coords$postal[indices[i]] <- postal_codes[i]
}
```

#### 3.2.6.2 Join into main apsatial data frame

```{r}
#| eval: false
rs_coords <- left_join(resale, postal_coords, by = c('address' = 'address'))
```

#### 3.2.6.3 Convert to sf object

```{r}
#| eval: false
rs_coords <- st_as_sf(rs_coords, 
                      coords = c("longitude", "latitude"),
                      crs = 3414)
```

#### 3.2.6.4 Visualise resale price

```{r}
#| eval: false
plot(rs_coords["resale_price"], key.pos = 4)
```

![](plot_resale.png){width="1215"}

Although this is simply an initial visualisation of the dataset, it shows a brief idea of the spread of the sales across Singapore. There is a slight clustering near the central region indicating the prices are different from the rest of the region. This is a useful indicator for variable selection.

### 3.2.7 Retain relevant fields

```{r}
#| eval: false
rs_coords <- subset(rs_coords, 
                    select = c(month, town, storey_num, floor_area_sqm, remaining_lease, resale_price))
```

### 3.2.8 Write file to RDS

```{r}
#| eval: false
write_rds(rs_coords, "data/aspatial/rds/resale.rds")
```

### 3.2.9 Read RDS file

```{r}
resale <- read_rds("data/aspatial/rds/resale.rds")
```

## 3.3 Geospatial Data

The geospatial data used is the base map layer of Singapore and locational factors. For ease of use, the factors will be grouped by category (transport, education, sports, amenities and others).

| Category      | Geospatial Factor    | Reason |
|---------------|----------------------|--------|
| **Transport** | Bus Stop             |        |
|               | MRT                  |        |
| **Education** | Kindergartens        |        |
|               | Childcare            |        |
|               | Primary Schools      |        |
|               | Good Primary Schools |        |
| **Sports**    | Sports Facilities    |        |
|               | Parks                |        |
|               | Gym                  |        |
|               | Water Sites          |        |
| **Amenities** | Hawker Center        |        |
|               | Supermarket          |        |
|               | Eldercare            |        |
| **Others**    | CBD Area             |        |
|               | Waste Disposal       |        |
|               | Active Cemeteries    |        |
|               | Historic Sites       |        |

### 3.3.1 Load Data and Transform CRS

Store token for using onemap api

```{r}
token <- "your token"
```

::: panel-tabset
#### Base Map

```{r}
mpsz <- st_read(dsn = "data/geospatial/base", layer="MP14_SUBZONE_WEB_PL") %>%
  st_transform(crs = 3414)
```

#### Transport

**Bus Stop**

```{r}
busstop <- st_read(dsn = "data/geospatial/transport/BusStop", layer="BusStop") %>%
  st_transform(crs = 3414) %>%
  select(1)
```

**MRT**

```{r}
#| eval: false
#| code-fold: true
#extract MRT data and save as shapefile
mrt <- st_read(dsn= "data/geospatial/transport/MRT/lta-mrt-station-exit-kml.kml") |> 
  st_zm()

st_write(obj = mrt,
         dsn = "data/geospatial/transport/MRT",
         layer = "MRT",
         driver = "ESRI Shapefile",
         append = FALSE)
```

```{r}
#read shapefile
mrt <- st_read(dsn= "data/geospatial/transport/MRT", layer = "MRT") %>%
  st_transform(crs = 3414) %>%
  select(1)
```

#### Education

**Kindergartens**

```{r}
#| eval: false
#| code-fold: true
#extract kindergarten data and save as shapefile
kindergartens<-get_theme(token,"kindergartens")
kindergartens <- st_as_sf(kindergartens, coords=c("Lng", "Lat"), crs=4326)

st_write(obj = kindergartens,
         dsn = "data/geospatial/education/kindergartens",
         layer = "kindergartens",
         driver = "ESRI Shapefile")
```

```{r}
kindergartens <- st_read(dsn = "data/geospatial/education/kindergartens", layer = "kindergartens") %>%
  st_transform(crs = 3414) %>%
  select(1)
```

**Childcare centers**

```{r}
#| eval: false
#| code-fold: true
#extract childcare center data and save as shapefile
childcare<-get_theme(token,"childcare")
childcare <- st_as_sf(childcare, coords=c("Lng", "Lat"), crs=4326)

st_write(obj = childcare,
         dsn = "data/geospatial/education/childcare",
         layer = "childcare",
         driver = "ESRI Shapefile")
```

```{r}
childcare <- st_read(dsn = "data/geospatial/education/childcare", layer = "childcare") %>%
  st_transform(crs = 3414) %>%
  select(1)
```

**Primary school**

```{r}
#| eval: false
#| code-fold: true
primary_schools <- read.csv("data/geospatial/education/primary_schools/general-information-of-schools.csv") |> 
  filter(mainlevel_code=="PRIMARY") |> 
  select(school_name, address, postal_code)


#dataframe to store api data
coords <- data.frame()

for (i in primary_schools$postal_code) {
  
  r <- GET('https://developers.onemap.sg/commonapi/search?',
           query=list(searchVal=i,
                     returnGeom='Y',
                     getAddrDetails='N'))
  
  data <- fromJSON(rawToChar(r$content))
  found <- data$found
  res <- data$results
  
  if (found > 0){
      lat <- res[[1]]$LATITUDE
      lng <- res[[1]]$LONGITUDE
      
      new_row <- data.frame(postal = as.numeric(i), latitude = lat, longitude = lng)
  }
  else {
    new_row <- data.frame(postal = as.numeric(i), latitude = NA, longitude = NA)
  }
  coords <- rbind(coords, new_row)
}

#There are 3 missing coordinate data for postal codes 88256, 99757 and 99840
#This is because the codes have 5 instead of 6 digits and need 0 padding

coords <- na.omit(coords)

for (i in c("088256", "099757", "099840")) {
  r <- GET('https://developers.onemap.sg/commonapi/search?',
           query=list(searchVal=i,
                     returnGeom='Y',
                     getAddrDetails='N'))
  
  res <- fromJSON(rawToChar(r$content))$results
  new_row <- data.frame(postal = as.numeric(i), latitude = res[[1]]$LATITUDE, longitude = res[[1]]$LONGITUDE)
  coords <- rbind(coords, new_row)
}


#add coordinate data into dataframe
primary_schools <- left_join(primary_schools, coords, by = c('postal_code' = 'postal'))

#store as sf object
primary_schools <- st_as_sf(primary_schools, coords=c("longitude", "latitude"), crs=4326)

#save as shapefile
st_write(obj = primary_schools,
         dsn = "data/geospatial/education/primary_schools",
         layer = "primary_schools",
         driver = "ESRI Shapefile")
```

```{r}
primary_schools <- st_read(dsn = "data/geospatial/education/primary_schools", layer = "primary_schools") %>%
  st_transform(crs = 3414) %>%
  select(1)
```

**Good primary school**

The top 10 schools have been selected from [here](https://schlah.com/primary-schools). Although this is 2020 data, it's ranking structure was more holistic as it was not solely based on GEP.

```{r}
#| eval: false
#| code-fold: true
school_list <- toupper(c("Nanyang Primary School", "Tao Nan School", "Catholic High School", "Nan Hua Primary School", "St. Hilda's Primary School", "Henry Park Primary School", "Anglo-Chinese School (Primary)", "Raffles Girls' Primary School", "Pei Hwa Presbyterian Primary School", "Chij St. Nicholas Girls' School"))

good_primary_schools <- primary_schools %>%
  filter(schl_nm %in% school_list)


#There is a discrepency between the way Catholic High School and Chij St. Nicholas Girls' School are mentioned in the school list on the website but not in the list imported from onemap api. To simplify this, the next two best schools will be selected.

school_list <- toupper(c("Rosyth School", "Kong Hwa School"))

good_primary_schools <- rbind(good_primary_schools, primary_schools %>% filter(schl_nm %in% school_list))

#save as shapefile
st_write(obj = good_primary_schools,
         dsn = "data/geospatial/education/good_primary_schools",
         layer = "good_primary_schools",
         driver = "ESRI Shapefile")
```

```{r}
good_primary_schools <- st_read(dsn = "data/geospatial/education/good_primary_schools", layer = "good_primary_schools") %>%
  st_transform(crs = 3414) %>%
  select(1)
```

#### Sports

**Sports Facilities**

```{r}
#| eval: false
#| code-fold: true
#extract sports facilities data and save as shapefile
sport_facilities <- get_theme(token,"sportsg_sport_facilities")

#Longitute column contains "longitute|latitude" which needs to be cleaned
sport_facilities <- sport_facilities %>%
  mutate(Lng=str_extract(Lng, "\\d+\\.?\\d*")) %>%
  select("NAME", "Lng", "Lat")

sport_facilities <- st_as_sf(sport_facilities, coords=c("Lng", "Lat"), crs=4326)

# creating a saved sf object in data file for easy reference
st_write(obj = sport_facilities,
         dsn = "data/geospatial/sports/sport_facilities",
         layer = "sport_facilities",
         driver = "ESRI Shapefile")
```

```{r}
sport_facilities <- st_read(dsn = "data/geospatial/sports/sport_facilities", layer = "sport_facilities") %>%
  st_transform(crs = 3414) %>%
  select(1)
```

**Parks**

```{r}
#| eval: false
#| code-fold: true
#extract park data and save as shapefile
parks <- st_read(dsn= "data/geospatial/sports/parks/parks.kml") |> 
  st_zm()

st_write(obj = parks,
         dsn = "data/geospatial/sports/parks",
         layer = "parks",
         driver = "ESRI Shapefile",
         append = FALSE)
```

```{r}
#read shapefile
parks <- st_read(dsn= "data/geospatial/sports/parks", layer = "parks") %>%
  st_transform(crs = 3414) %>%
  select(1)
```

**Gyms**

```{r}
#| eval: false
#| code-fold: true
#extract gym data and save as shapefile
gyms <- st_read(dsn= "data/geospatial/sports/gyms/gyms-sg-kml.kml") |> 
  st_zm()

st_write(obj = gyms,
         dsn = "data/geospatial/sports/gyms",
         layer = "gyms",
         driver = "ESRI Shapefile",
         append = FALSE)
```

```{r}
#read shapefile
gyms <- st_read(dsn= "data/geospatial/sports/gyms", layer = "gyms") %>%
  st_transform(crs = 3414) %>%
  select(1)
```

**Water Sites**

```{r}
#| eval: false
#| code-fold: true
#extract gym data and save as shapefile
watersites <- st_read(dsn= "data/geospatial/sports/watersites/abc-water-sites.kml") |> 
  st_zm()

st_write(obj = watersites,
         dsn = "data/geospatial/sports/watersites",
         layer = "watersites",
         driver = "ESRI Shapefile",
         append = FALSE)
```

```{r}
#read shapefile
watersites <- st_read(dsn= "data/geospatial/sports/watersites", layer = "watersites") %>%
  st_transform(crs = 3414) %>%
  select(1)
```

#### Amenities

**Hawker centers**

```{r}
#| eval: false
#| code-fold: true
#extract gym data and save as shapefile
hawker_centers <- st_read(dsn= "data/geospatial/amenities/hawker_centers/hawker-centres-kml.kml") |> 
  st_zm()

st_write(obj = hawker_centers,
         dsn = "data/geospatial/amenities/hawker_centers",
         layer = "hawker_centers",
         driver = "ESRI Shapefile",
         append = FALSE)
```

```{r}
#read shapefile
hawker_centers <- st_read(dsn= "data/geospatial/amenities/hawker_centers", layer = "hawker_centers") %>%
  st_transform(crs = 3414) %>%
  select(1)
```

**Supermarkets**

```{r}
#| eval: false
#| code-fold: true
#extract gym data and save as shapefile
supermarkets <- st_read(dsn= "data/geospatial/amenities/supermarkets/supermarkets-kml.kml") |> 
  st_zm()

st_write(obj = supermarkets,
         dsn = "data/geospatial/amenities/supermarkets",
         layer = "supermarkets",
         driver = "ESRI Shapefile",
         append = FALSE)
```

```{r}
#read shapefile
supermarkets <- st_read(dsn= "data/geospatial/amenities/supermarkets", layer = "supermarkets") %>%
  st_transform(crs = 3414) %>%
  select(1)
```

**Eldercare**

```{r}
#| eval: false
#| code-fold: true
#extract eldercare center data and save as shapefile
eldercare <-get_theme(token,"eldercare")
eldercare <- st_as_sf(eldercare, coords=c("Lng", "Lat"), crs=4326)

st_write(obj = eldercare,
         dsn = "data/geospatial/amenities/eldercare",
         layer = "eldercare",
         driver = "ESRI Shapefile")
```

```{r}
eldercare <- st_read(dsn = "data/geospatial/amenities/eldercare", layer = "eldercare") %>%
  st_transform(crs = 3414) %>%
  select(1)
```

#### Others

**CBD Area**

As the 'Downtown Core' is also referred to as the Central Business District (CBD), the coordinates of 'Downtown Core' shall be used. Based on the information [here](https://www.latlong.net/place/downtown-core-singapore-20616.html), the latitude is 1.287953 and longitude is 103.851784

```{r}
cbd <- st_as_sf(data.frame(name = c("CBD Area"), latitude = c(1.287953), longitude = c(103.851784)),
                coords = c("longitude", "latitude"),
                crs = 3414)
```

**Waste Disposal sites**

```{r}
#| eval: false
#| code-fold: true
#extract waste disposal data and save as shapefile
waste_disposal <- st_read(dsn= "data/geospatial/others/waste_disposal/waste-treatment-kml.kml") |> 
  st_zm()

st_write(obj = supermarkets,
         dsn = "data/geospatial/others/waste_disposal",
         layer = "waste_disposal",
         driver = "ESRI Shapefile",
         append = FALSE)
```

```{r}
#read shapefile
waste_disposal <- st_read(dsn= "data/geospatial/others/waste_disposal", layer = "waste_disposal") %>%
  st_transform(crs = 3414) %>%
  select(1)
```

**Active Cemeteries**

```{r}
#| eval: false
#| code-fold: true
#extract active cemeteries data and save as shapefile
cemeteries <- st_read(dsn= "data/geospatial/others/active_cemeteries/active-cemeteries-kml.kml") |> 
  st_zm()

st_write(obj = cemeteries,
         dsn = "data/geospatial/others/active_cemeteries",
         layer = "cemeteries",
         driver = "ESRI Shapefile",
         append = FALSE)
```

```{r}
#read shapefile
cemeteries <- st_read(dsn= "data/geospatial/others/active_cemeteries", layer = "cemeteries") %>%
  st_transform(crs = 3414) %>%
  select(1)
```

**Historic Sites**

```{r}
#| eval: false
#| code-fold: true
#extract historic sites data and save as shapefile
historic_sites <- st_read(dsn= "data/geospatial/others/historic_sites/historic-sites-kml.kml") |> 
  st_zm()

st_write(obj = historic_sites,
         dsn = "data/geospatial/others/historic_sites",
         layer = "historic_sites",
         driver = "ESRI Shapefile",
         append = FALSE)
```

```{r}
#read shapefile
historic_sites <- st_read(dsn= "data/geospatial/others/historic_sites", layer = "historic_sites") %>%
  st_transform(crs = 3414) %>%
  select(1)
```
:::

### 3.3.2 Check for Invalid Geometries

#### 3.3.2.1 Base layer

```{r}
#| code-fold: true
cat("There are", length(which(st_is_valid(mpsz) == FALSE)) , "invalid geometries in the base layer. This shall be resolved in the following step.")
```

```{r}
mpsz <- st_make_valid(mpsz)
```

```{r}
#| code-fold: true
cat("There are now", length(which(st_is_valid(mpsz) == FALSE)) , "invalid geometries in the base layer.")
```

#### 3.3.2.2 Geospatial Factors

```{r}
#| code-fold: true
df_list <- c("busstop", "cbd", "cemeteries", "childcare", "eldercare", "good_primary_schools", "gyms", "hawker_centers", "historic_sites", "kindergartens", "mrt", "parks", "primary_schools", "sport_facilities", "supermarkets", "waste_disposal", "watersites")

c = 0 

for(i in df_list) {
  c = c + length(which(st_is_valid(eval(parse(text = i))) == FALSE))
}

cat("There are", c , "invalid geometries in the geospatial factors")
```

### 3.3.3 Check for Missing Values

#### 3.3.3.1 Base layer

```{r}
#| code-fold: true
cat("There are", sum(is.na(mpsz)) , "missing values in the base layer.")
```

#### 3.3.3.2 Geospatial Factors

```{r}
#| code-fold: true
c = 0 
for(i in df_list) {
  c = c + sum(is.na(mpsz))
}
cat("There are", c , "missing values in the geospatial factors.")
```

### 3.3.4 Verify CRS

#### 3.3.4.1 Base layer

```{r}
st_crs(mpsz)[1]$input
```

#### 3.3.4.2 Geospatial Factors

```{r}
#| code-fold: true
for(i in df_list) {
  cat(i, st_crs(eval(parse(text = i)))[1]$input, "\n")
}

```

## 3.4 Visualise Data

::: panel-tabset
#### Transport

```{r}
#| eval: false
#| code-fold: true
tm_shape(mpsz) +
  tm_borders(alpha = 0.5) +
  tmap_options(check.and.fix = TRUE) +
tm_shape(busstop) +
  tm_dots(col="azure3", alpha=0.5) +
tm_shape(mrt) +
  tm_dots(col="yellow", alpha=1)+
  tm_layout(main.title = "Transport",
          main.title.position = "center")
```

![](transport){width="1213"}

#### Education

```{r}
#| eval: false
#| code-fold: true
tm_shape(mpsz) +
  tm_borders(alpha = 0.5) +
  tmap_options(check.and.fix = TRUE) +
tm_shape(childcare) +
  tm_dots(col="black", alpha=0.2) +
tm_shape(primary_schools) +
  tm_dots(col="lightskyblue3", alpha=0.5)+
tm_shape(kindergartens) +
  tm_dots(col="lightslateblue", alpha=0.5) +
tm_shape(good_primary_schools) +
  tm_dots(col="red", alpha=1)+
tm_shape(mpsz) +
  tm_borders(alpha = 0.01) +
  tm_layout(main.title = "Education",
          main.title.position = "center")
```

![](education){width="1213"}

#### Sports

```{r}
#| eval: false
#| code-fold: true
tm_shape(mpsz) +
  tm_borders(alpha = 0.5) +
  tmap_options(check.and.fix = TRUE) +
tm_shape(sport_facilities) +
  tm_dots(col="violet", alpha=1) +
tm_shape(parks) +
  tm_dots(col="mediumseagreen", alpha=0.5) + 
tm_shape(gyms) +
  tm_dots(col="azure3", alpha=0.7) +
tm_shape(watersites) +
  tm_dots(col="skyblue3", alpha=1) +
  tm_layout(main.title = "Sports",
          main.title.position = "center")
```

![](sports){width="1213"}

#### Amenities

```{r}
#| eval: false
#| code-fold: true
tm_shape(mpsz) +
  tm_borders(alpha = 0.5) +
  tmap_options(check.and.fix = TRUE) +
tm_shape(hawker_centers) +
  tm_dots(col="firebrick3", alpha=1) +
tm_shape(supermarkets) +
  tm_dots(col="olivedrab", alpha=0.5) + 
tm_shape(eldercare) +
  tm_dots(col="tan", alpha=0.7) +
  tm_layout(main.title = "Amenities",
          main.title.position = "center")
```

![](amenities){width="1213"}

#### Others

```{r}
#| eval: false
#| code-fold: true
tm_shape(mpsz) +
  tm_borders(alpha = 0.5) +
  tmap_options(check.and.fix = TRUE) +
tm_shape(cbd) +
  tm_dots(col="purple", alpha=1) +
tm_shape(waste_disposal) +
  tm_dots(col="coral3", alpha=0.5) + 
tm_shape(cemeteries) +
  tm_dots(col="gray20", alpha=1) +
tm_shape(historic_sites) +
  tm_dots(col="darkseagreen2", alpha=1) +
  tm_layout(main.title = "Others",
          main.title.position = "center")
```

![](others){width="1213"}
:::

# 4.0 Regression Modelling

## 4.1 Proximity Calculation

```{r}
for(i in df_list) {
  dist_matrix <- st_distance(resale, eval(parse(text = i))) |> drop_units()
  resale[,paste("PROX_",toupper(i), sep = "")] <- rowMins(dist_matrix)
}
```

## 4.2 Count in range Calculation

```{r}
num_list <- c("kindergartens", "childcare", "busstop", "primary_schools")
radius_list <- c(350, 350, 350, 1000)
for(i in 1:4) {
  dist_matrix <- st_distance(resale, eval(parse(text = num_list[i]))) |> drop_units()
  resale[,paste("NUM_",toupper(num_list[i]), sep = "")] <- rowSums(dist_matrix <= radius_list[i])
}
```

## 4.3 Save checkpoint as RDS file

Save file

```{r}
write_rds(resale, "data/rds/resale.rds")
```

Read file

```{r}
resale <- read_rds("data/rds/resale.rds")
```

## 4.4 Data Preparation

### 4.4.1 Correlation Matrix

To check for multicolinearity

```{r}
#| code-fold: true
corr <- resale |>
  st_drop_geometry() |>
  select_if(is.numeric) |>
  select(-resale_price)
  
corrplot(cor(corr), 
         diag = FALSE,
         order = "AOE",
         tl.pos = "td",
         tl.cex = 0.5,
         method = "number", 
           type = "upper")
```

![](corr_matrix.png)

While variables don't have perfect correlation with other variables, PROX_WATERSITES, PROX_WASTE_DISPOSAL, PROX_CEMETERIES, PROX_BUSSTOP, PROX_HISTORIC_SITES, PROX_GYMS, PROX_CHILDCARE, PROX_ELDERCARE, PROX_WATERSITES have high correlation (\> 0.99) with other variables so they will be discarded

```{r}
resale <- subset(resale, select = -c(PROX_WATERSITES, PROX_WASTE_DISPOSAL, PROX_CEMETERIES, PROX_SPORT_FACILITIES,  PROX_SUPERMARKETS, PROX_BUSSTOP, PROX_HISTORIC_SITES, PROX_HAWKER_CENTERS, PROX_GYMS, PROX_CHILDCARE, PROX_ELDERCARE, PROX_WATERSITES))
```

### 4.4.2 Data Sampling

Seperate data into train and test. Train data - all transactions between Jan 01 2021 to Dec 31 2021. Test data - Jan 01 2023 to Feb 28 2023

```{r}
train_data<-resale |> 
  filter(month >= "2021-01" & month <= "2022-12")

test_data<-resale |> 
  filter(month >= "2023-01" & month <= "2023-02")
```

#### 4.4.2.1 Save Train and Test data as Checkpoint

```{r}
write_rds(train_data, "data/rds/train_data.rds")
write_rds(test_data, "data/rds/test_data.rds")
```

## 4.5 OLS method

```{r}
mlr<- lm(resale_price ~ storey_num + floor_area_sqm + remaining_lease + PROX_KINDERGARTENS + PROX_CBD + PROX_MRT + NUM_KINDERGARTENS + NUM_CHILDCARE + NUM_BUSSTOP + NUM_PRIMARY_SCHOOLS, data=train_data)

# save result
write_rds(mlr, "data/rds/mlr.rds")
```

Summary

```{r}
mlr<-read_rds("data/rds/mlr.rds")
gtsummary::tbl_regression(mlr)
```
